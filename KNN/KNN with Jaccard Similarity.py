# -*- coding: utf-8 -*-
"""M22MA003_Assig2_Question1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eX6UGou2REEeiqN4ccnqA4tLoUs8AgAL
"""

!pip install psutil

import psutil
import warnings
warnings.filterwarnings('ignore')
from matplotlib import pyplot as plt

import numpy as np
from keras.datasets import mnist
(X_train_data, y_train_data), (X_test_data, y_test_data) = mnist.load_data()
X_train = X_train_data.reshape(-1, 28*28)
y_train = y_train_data
X_test = X_test_data.reshape(-1, 28*28)
y_test = y_test_data

print(X_train[:].shape, y_train.shape, X_test.shape, y_test.shape)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.metrics import accuracy_score
import time

## K-neighbour vs Accuarcy plot
def accuracy_plot(accuracy_list,training_time_list,prediction_time_list,label):
  plt.figure(figsize = (5,3))
  k = np.linspace(1,5,5)
  # Create a figure with two subplots side by side
  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 3))
  ax1.plot(k, accuracy_list)
  ax1.set_title(label[0])
  ax2.plot(k, training_time_list)
  ax2.set_title(label[1])
  ax3.plot(k, prediction_time_list)
  ax3.set_title(label[2])
  plt.subplots_adjust(wspace=0.3)
  plt.show()
  # plt.plot(range(1, epoches*(len(train_dataloader)*BATCH_SIZE) + 1), train)
  # plt.plot(range(5), list, label = "K", color="blue")
  # plt.plot(range(5), list, label = "K", color="blue")
  # plt.xlabel(label)
  # plt.ylabel("Test Accuracy")
  # plt.title(f"K-neighbour vs {label}")
  # plt.show()
# load the MNIST dataset
# digits = load_digits()

# split the dataset into training and testing sets
# X_train, y_train = digits.data[:1500], digits.target[:1500]
# X_test, y_test = digits.data[1500:], digits.target[1500:]

# loop over different k values
def jaccard_knn(X_train,y_train,X_test,y_test,k):
    print(f"Number of Training samples : {X_train.shape[0]} , Number of Test samples :  {X_test.shape[0]}")
    accuracy_list = []
    training_time_list = []
    prediction_time_list = []
    peak_RAM_list = []
    for k in range(1, (k+1)):
        # create KNN classifier using Jaccard similarity
        knn = KNeighborsClassifier(n_neighbors=k, metric='jaccard')
        
        # fit the model and time it
        start_time = time.time()
        knn.fit(X_train, y_train)
        end_time = time.time()
        training_time = end_time - start_time
        
        # make a prediction and time it
        start_time = time.time()
        y_pred = knn.predict(X_test)
        end_time = time.time()
        prediction_time = end_time - start_time
        
        # calculate the classification accuracy
        accuracy = accuracy_score(y_test, y_pred)
        
        # print the results
        print(f"K={k}, Accuracy={accuracy:.4f}, Training Time={training_time:.4f}, Prediction Time={prediction_time:.4f}")
        accuracy_list.append(accuracy)
        training_time_list.append(training_time)
        prediction_time_list.append(prediction_time)
    label=("Accuracy","Training Time","Prediction Time")
    accuracy_plot(accuracy_list,training_time_list,prediction_time_list,label)
    
    # accuracy_plot(training_time_list, "Training Time")
    # accuracy_plot(prediction_time_list, "Prediction Time")

def get_peak_memory(k,num_train,num_test):
    process = psutil.Process()
    jaccard_knn(X_train[:num_train],y_train[:num_train],X_test[:num_test],y_test[:num_test],k)
    memory_info = process.memory_info()
    peak_memory = process.memory_info().rss / 1024 / 1024  # convert bytes to MB
    print(f"Peak memory usage: {peak_memory} bytes")
    print("****************************************************************************************************************************************************************")
sample_params=((10000,1400),(20000,3300),(30000,5000),(60000,10000))
# sample_params=((1000,40),)
for num_train,num_test in sample_params:
    get_peak_memory(5,num_train,num_test)

# get_peak_memory(k=5,num_train=10000,num_test=1400)

# get_peak_memory(k=5,num_train=20000,num_test=3300)

# get_peak_memory(k=5,num_train=30000,num_test=5000)

# get_peak_memory(k=5,num_train=-1,num_test=-1)

