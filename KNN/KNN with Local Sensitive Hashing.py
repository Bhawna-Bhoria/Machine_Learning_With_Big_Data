# -*- coding: utf-8 -*-
"""M22MA003_Assig2_Question2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ASSlkdQwx-BjsmcU8yI522gAAtHMK0HY
"""

!pip install datasketch
!pip install psutils

# import torch
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

import numpy as np
import psutil
import warnings
warnings.filterwarnings('ignore')
from matplotlib import pyplot as plt
from keras.datasets import mnist
from datasketch import MinHash, MinHashLSH

# Load MNIST dataset
(x_train_data, y_train), (x_test_data, y_test) = mnist.load_data()
# x_train_data=torch.tensor(x_train_data)
# y_train=torch.tensor(y_train)
# y_train=y_train.t
# X_train_data=X_train_data.to(device)
# Reshape and normalize the images
x_train = x_train_data.reshape(-1, 28*28)
x_test = x_test_data.reshape(-1, 28*28)
# Define threshold value
threshold = 0

# Convert images to binary data using threshold
X_train_binary = np.where(x_train > threshold, 1, 0)
X_test_binary = np.where(x_test > threshold, 1, 0)

x_train_sub = x_train[:150]
y_train_sub = y_train[:150]
x_test_sub = x_test[:2]
y_test_sub = y_test[:2]

x_train_sub.shape, y_train_sub.shape, x_test_sub.shape, y_test_sub.shape

X_train_binary_sub = X_train_binary[:2]
y_train_binary_sub = y_train[:2]
X_test_binary_sub = X_test_binary[:20]
y_test_binary_sub = y_test[:20]

X_train_binary_sub.shape, y_train_sub.shape, X_test_binary_sub.shape, y_test_sub.shape

import numpy as np
from keras.datasets import mnist

# def _hash_func(d):
#     return hash32(d)

def my_metric40_s8(image1, image2):

    # from datasketch import MinHash, MinHashLSH

    # Load MNIST dataset
    # (x_train, y_train), (x_test, y_test) = mnist.load_data()

    # # Reshape and normalize the images
    # x_train = x_train.reshape(-1, 28*28) / 255
    # x_test = x_test.reshape(-1, 28*28) / 255
    # Define number of hash functions and number of bands and size of each band for LSH
    num_perm = 40
    num_bands = (8,5)
    # print(f"image1 is {image1} and image2 is {image2}")
    # Choose two random images from the test set
    # index1, index2 = np.random.choice(x_test.shape[0], size=2, replace=False)
    # image1_b = x_test[index1]
    # image2_b = x_test[index2]
    # image1 = np.where(image1_b > threshold, 1, 0)
    # image2 = np.where(image2_b > threshold, 1, 0)
    image1 = image1/255
    image2 = image2/255
    # Initialize MinHash objects for the two images
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    # print(f"minhash1 is {minhash1} and minhash2 is {minhash2}")
    # Add the pixel values of each image to the corresponding MinHash object
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    # print(minhash1.hashvalues)
    # print(minhash2.hashvalues)
    # Initialize LSH index and add the MinHash objects
    lsh = MinHashLSH(threshold=0.8,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    # Calculate Jaccard similarity score between the two images
    similarity_score = minhash1.jaccard(minhash2)
    # print(lsh.b,lsh.h,lsh.hashtables,lsh.hashranges,lsh.hashfunc,lsh.keys,lsh.prepickle,lsh.r)
    # Retrieve candidate matches for the first image using LSH
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    # print("Image 1 index: {}".format(index1))
    # print("Image 2 index: {}".format(index2))
    # print("Similarity score: {}".format(similarity_score))
    # print("Candidate matches for image 1: {}".format(matches1))
    # print("Candidate matches for image 2: {}".format(matches2))
    if similarity_score>0.8:
        return 0
    else:
        return (1-similarity_score)

def my_metric50_s8(image1, image2):
    num_perm = 50
    num_bands = (10,5)
    image1 = image1/255
    image2 = image2/255
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    lsh = MinHashLSH(threshold=0.8,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    similarity_score = minhash1.jaccard(minhash2)
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    if similarity_score>0.8:
        return 0
    else:
        return (1-similarity_score)

def my_metric60_s8(image1, image2):
    num_perm = 60
    num_bands = (12,5)
    image1 = image1/255
    image2 = image2/255
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    lsh = MinHashLSH(threshold=0.8,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    similarity_score = minhash1.jaccard(minhash2)
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    if similarity_score>0.8:
        return 0
    else:
        return (1-similarity_score)

def my_metric40_s9(image1, image2):
    num_perm = 40
    num_bands = (10,5)
    image1 = image1/255
    image2 = image2/255
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    lsh = MinHashLSH(threshold=0.9,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    similarity_score = minhash1.jaccard(minhash2)
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    if similarity_score>0.9:
        return 0
    else:
        return (1-similarity_score)


def my_metric50_s9(image1, image2):
    num_perm = 50
    num_bands = (10,5)
    image1 = image1/255
    image2 = image2/255
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    lsh = MinHashLSH(threshold=0.9,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    similarity_score = minhash1.jaccard(minhash2)
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    if similarity_score>0.9:
        return 0
    else:
        return (1-similarity_score)

def my_metric60_s9(image1, image2):
    num_perm = 60
    num_bands = (12,5)
    image1 = image1/255
    image2 = image2/255
    minhash1 = MinHash(num_perm=num_perm)
    minhash2 = MinHash(num_perm=num_perm)
    for pixel in image1:
        minhash1.update(str(pixel).encode('utf8'))
    for pixel in image2:
        minhash2.update(str(pixel).encode('utf8'))
    lsh = MinHashLSH(threshold=0.9,num_perm=num_perm, params=num_bands)
    lsh.insert("image1", minhash1)
    lsh.insert("image2", minhash2)
    similarity_score = minhash1.jaccard(minhash2)
    matches1 = lsh.query(minhash1)
    matches2 = lsh.query(minhash2)
    if similarity_score>0.9:
        return 0
    else:
        return (1-similarity_score)

my_metric40_s8(x_train_sub[0],x_train_sub[1])

x_train_sub.shape

y_train_sub.shape

from sklearn.neighbors import KNeighborsClassifier
from scipy.spatial.distance import euclidean
from sklearn.metrics import accuracy_score
import time

# Define a custom metric function
def my_metric2(x1, x2):
    # Define your own distance metric here
    print(euclidean(x1, x2))
    return euclidean(x1, x2)  # Example: Euclidean distance
def draw_plot(accuracy_list,training_time_list,prediction_time_list,label):
  plt.figure(figsize = (5,3))
  k = np.linspace(1,5,5)
  # Create a figure with two subplots side by side
  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 3))
  ax1.plot(k, accuracy_list)
  ax1.set_title(label[0])
  ax2.plot(k, training_time_list)
  ax2.set_title(label[1])
  ax3.plot(k, prediction_time_list)
  ax3.set_title(label[2])
  plt.subplots_adjust(wspace=0.3)
  plt.show()
# Load your data and split into training and testing sets
def call_knn(x_train,y_train,x_test,y_test,k,metric_type):
    print(f"Number of Training samples : {x_train.shape[0]} , Number of Test samples :  {x_test.shape[0]}")
    accuracy_list = []
    training_time_list = []
    prediction_time_list = []
    # Create an instance of the KNeighborsClassifier
    for k in range(1,k+1):
        knn = KNeighborsClassifier(n_neighbors=k, metric=metric_type)
        # knn = KNeighborsClassifier(n_neighbors=5, metric=my_metric2)
        # Train the model on the training data
        # knn.fit(X_train_binary_sub, y_train_sub)
        start_time = time.time()
        knn.fit(x_train, y_train)
        end_time = time.time()
        training_time = end_time - start_time
        # num_classes = knn.classes_
        # print(num_classes) 
        # Test the model on the testing data
        start_time = time.time()
        y_pred = knn.predict(x_test)
        end_time = time.time()
        prediction_time = end_time - start_time
        accuracy = accuracy_score(y_test, y_pred)
        print(f"K={k}, Accuracy={accuracy:.4f}, Training Time={training_time:.4f}, Prediction Time={prediction_time:.4f}")
        accuracy_list.append(accuracy)
        training_time_list.append(training_time)
        prediction_time_list.append(prediction_time)
    label=("Accuracy","Training Time","Prediction Time")
    draw_plot(accuracy_list,training_time_list,prediction_time_list,label)
    return accuracy_list
def get_peak_memory(k,num_train,num_test,metric_type):
    process = psutil.Process()
    accuracy_list = np.asarray(call_knn(x_train[:num_train],y_train[:num_train],x_test[:num_test],y_test[:num_test],k,metric_type))
    accuracy_mean = np.mean(accuracy_list)
    accuracy_std_dev = np.std(accuracy_list)
    memory_info = process.memory_info()
    peak_memory = process.memory_info().rss / 1024 / 1024  # convert bytes to MB
    print(f"Peak memory usage: {peak_memory:.4f} MB , Accuracy Mean is {accuracy_mean:.4f} , Accuracy Standard Deviation is {accuracy_std_dev:.4f}")
    print("****************************************************************************************************************************************************************")
    
sample_params=((1000,10),(1200,12),(1400,14),(1600,16))
# sample_params=((5,2),)
for num_train,num_test in sample_params:
    get_peak_memory(5,num_train,num_test,my_metric40_s8)













# y_train_sub,y_test_sub,preds,accuracy

# from datasketch import MinHash

# data1 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
# data2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]

# m1, m2 = MinHash(), MinHash()
# for d in data1:
#     m1.update(str(d).encode('utf8'))
# for d in data2:
#     m2.update(str(d).encode('utf8'))
# print("Estimated Jaccard for data1 and data2 is", m1.jaccard(m2))

# s1 = set(data1)
# s2 = set(data2)
# actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))
# print("Actual Jaccard for data1 and data2 is", actual_jaccard)